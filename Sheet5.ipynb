{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sheet5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "FS4QvsXQRVmH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install -U -q scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UEGizOzBmCY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "#-----------------------------------\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#-----------------------------------\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile,join\n",
        "#-----------------------------------\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from urllib.request import urlretrieve\n",
        "#-----------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9lAbSzE8Odr6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ]
    },
    {
      "metadata": {
        "id": "WEx0XRNTOjRt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Question 1 solved 'Hand written'](https://i.ibb.co/F3rrkQv/image.png)\n",
        "![Question 1 solved 'Hand written'](https://i.ibb.co/PNDcy5z/image.png)\n",
        "\n",
        "\n",
        "![Question 1 solved 'Hand written'](https://i.ibb.co/p17f3Rv/55853711-315507942491266-4422435302505709568-n.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "IQczJfSZSrtu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ]
    },
    {
      "metadata": {
        "id": "YUEuequZSwVq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Use the Face-data set we used in Assignment 1.**"
      ]
    },
    {
      "metadata": {
        "id": "d0JIpStsSOxI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getImagesFormDataSet():\n",
        "  if not os.path.isfile('att_faces.tar.Z'):\n",
        "    print(\"Download file... \" +'att_faces.tar.Z' + \" ...\")\n",
        "    urlretrieve('http://www.cl.cam.ac.uk/Research/DTG/attarchive/pub/data/att_faces.tar.Z','att_faces.tar.Z')\n",
        "    print(\"File downloaded\")\n",
        "  if not os.path.isfile('/content/att_faces.tar.Z'):\n",
        "    print('File is unzipped')\n",
        "    !apt-get install p7zip-full\n",
        "    !p7zip -d att_faces.tar.Z\n",
        "    !tar -xvf att_faces.tar.Z\n",
        "  first_dir = False\n",
        "  full_list = list()\n",
        "  sub_directory_list = list()\n",
        "  sub_files = list()\n",
        "  labels = list()\n",
        "  data_matrix = list()\n",
        "  for x in os.walk('/content/orl_faces/'):\n",
        "    if(first_dir == False):\n",
        "      first_dir = True\n",
        "      continue\n",
        "    sub_directory_list.append(x[0])\n",
        "  sub_directory_list.sort()\n",
        "  for sub in sub_directory_list:\n",
        "    sub_files.append([(sub +\"/\"+f) for f in listdir(sub) if isfile(join(sub, f))])\n",
        "  for file in sub_files:\n",
        "    for x in file:\n",
        "      temp = x.replace(\"/content/orl_faces/s\", \"\")\n",
        "      labels.append(temp[0:temp.index('/')])\n",
        "      full_list.append((plt.imread(x)).reshape((10304)))\n",
        "  return np.asarray(full_list,dtype = \"int32\"),np.asarray(labels,dtype = \"int32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ilcq1xlby5b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Splitting Data into train and test\n",
        "def getTestAndTrainingSet(full_list,labels):\n",
        "  test_Datamatrix = []\n",
        "  test_Labelmatrix = []\n",
        "  train_Datamatrix = []\n",
        "  train_Labelmatrix = []\n",
        "\n",
        "  for i,index in zip(range (400),range(400)):\n",
        "    if(i % 2 == 1):\n",
        "      test_Datamatrix.append(full_list[index])\n",
        "      test_Labelmatrix.append(labels[index])\n",
        "    else:\n",
        "      train_Datamatrix.append(full_list[index])\n",
        "      train_Labelmatrix.append(labels[index])\n",
        "        \n",
        "  test_Datamatrix = np.asarray(test_Datamatrix,dtype = \"int32\")\n",
        "  test_Labelmatrix = np.asarray(test_Labelmatrix,dtype = \"int32\")\n",
        "  train_Datamatrix = np.asarray(train_Datamatrix,dtype = \"int32\")\n",
        "  train_Labelmatrix = np.asarray(train_Labelmatrix,dtype = \"int32\")\n",
        "  return test_Datamatrix,test_Labelmatrix,train_Datamatrix,train_Labelmatrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "th49pySecob1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1411
        },
        "outputId": "42e1d0ad-e318-4d98-e6e5-4c8bfbbae005"
      },
      "cell_type": "code",
      "source": [
        "full_list,labels = getImagesFormDataSet()\n",
        "test_Datamatrix,test_Labelmatrix,train_Datamatrix,train_Labelmatrix = getTestAndTrainingSet(full_list,labels)\n",
        "clf = GaussianNB()\n",
        "clf.fit(train_Datamatrix, train_Labelmatrix)\n",
        "print(\"Accuracy:\",accuracy_score(test_Labelmatrix, clf.predict(test_Datamatrix)))\n",
        "print (\"Confusion Matrix:\",confusion_matrix(test_Labelmatrix, clf.predict(test_Datamatrix)),sep=\"\\n\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.715\n",
            "Confusion Matrix:\n",
            "[[5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 0 0\n",
            "  0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            "  0 0 4 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 4 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 3 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0\n",
            "  0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 4 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 3 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 2 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0\n",
            "  1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 4 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 5 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ONif6a0Bh8Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ]
    },
    {
      "metadata": {
        "id": "OCy1x_TCBpBb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Compute the prior for the three classes.**"
      ]
    },
    {
      "metadata": {
        "id": "D6s45YkCuD8r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8072c1e8-8af7-475d-dbac-6028ee5c75c5"
      },
      "cell_type": "code",
      "source": [
        "c1 = np.array([[2,6],[3,5],[4,4],[5,3],[6,2],[6,4],[6,6],[8,4],[9,2],[9,3]])\n",
        "c2 = np.array([[3,3],[4,3],[4,5],[5,5],[7,3],[7,4],[7,5]])\n",
        "c3 = np.array([[7,2],[10,1],[10,3],[10,5],[11,3],[11,4],[12,2],[13,5]])\n",
        "print(\"C1 Prior:\",len(c1) / (len(c1) + len(c2) + len(c3)))\n",
        "print(\"C2 Prior:\",len(c2) / (len(c1) + len(c2) + len(c3)))\n",
        "print(\"C3 Prior:\",len(c3) / (len(c1) + len(c2) + len(c3)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C1 Prior: 0.4\n",
            "C2 Prior: 0.28\n",
            "C3 Prior: 0.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xDJK1iPJEBgi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Compute the mean and covariance matrix for C1, C2 and C3**"
      ]
    },
    {
      "metadata": {
        "id": "aWHZCU6KCTMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "0f4b8b4a-28b4-47b6-aea4-9e8fed907c47"
      },
      "cell_type": "code",
      "source": [
        "print(\"Mean of C1: [\",sum(c1[:,0]) / len(c1) ,\",\",sum(c1[:,1]) / len(c1),\"]\")\n",
        "print(\"Mean of C2: [\",np.around(sum(c2[:,0]) / len(c2),decimals=2) ,\",\",sum(c2[:,1]) / len(c2),\"]\")\n",
        "print(\"Mean of C3: [\",sum(c3[:,0]) / len(c3) ,\",\",sum(c3[:,1]) / len(c3),\"]\")\n",
        "print(\"------------------------------------------\")\n",
        "print(\"C1 Covariance:\",np.cov(c1),sep =\"\\n\")\n",
        "print(\"C2 Covariance:\",np.cov(c2),sep =\"\\n\")\n",
        "print(\"C3 Covariance:\",np.cov(c3),sep =\"\\n\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of C1: [ 5.8 , 3.9 ]\n",
            "Mean of C2: [ 5.29 , 4.0 ]\n",
            "Mean of C3: [ 10.5 , 3.125 ]\n",
            "------------------------------------------\n",
            "C1 Covariance:\n",
            "[[  8.    4.    0.   -4.   -8.   -4.    0.   -8.  -14.  -12. ]\n",
            " [  4.    2.    0.   -2.   -4.   -2.    0.   -4.   -7.   -6. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [ -4.   -2.    0.    2.    4.    2.    0.    4.    7.    6. ]\n",
            " [ -8.   -4.    0.    4.    8.    4.    0.    8.   14.   12. ]\n",
            " [ -4.   -2.    0.    2.    4.    2.    0.    4.    7.    6. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [ -8.   -4.    0.    4.    8.    4.    0.    8.   14.   12. ]\n",
            " [-14.   -7.    0.    7.   14.    7.    0.   14.   24.5  21. ]\n",
            " [-12.   -6.    0.    6.   12.    6.    0.   12.   21.   18. ]]\n",
            "C2 Covariance:\n",
            "[[ 0.   0.   0.   0.   0.   0.   0. ]\n",
            " [ 0.   0.5 -0.5  0.   2.   1.5  1. ]\n",
            " [ 0.  -0.5  0.5  0.  -2.  -1.5 -1. ]\n",
            " [ 0.   0.   0.   0.   0.   0.   0. ]\n",
            " [ 0.   2.  -2.   0.   8.   6.   4. ]\n",
            " [ 0.   1.5 -1.5  0.   6.   4.5  3. ]\n",
            " [ 0.   1.  -1.   0.   4.   3.   2. ]]\n",
            "C3 Covariance:\n",
            "[[12.5 22.5 17.5 12.5 20.  17.5 25.  20. ]\n",
            " [22.5 40.5 31.5 22.5 36.  31.5 45.  36. ]\n",
            " [17.5 31.5 24.5 17.5 28.  24.5 35.  28. ]\n",
            " [12.5 22.5 17.5 12.5 20.  17.5 25.  20. ]\n",
            " [20.  36.  28.  20.  32.  28.  40.  32. ]\n",
            " [17.5 31.5 24.5 17.5 28.  24.5 35.  28. ]\n",
            " [25.  45.  35.  25.  40.  35.  50.  40. ]\n",
            " [20.  36.  28.  20.  32.  28.  40.  32. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eMS1zDwnIkVJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Use the Naive Bayes classifier to classify the samples p1=(6,5) p2=(9,4) ,p3=(8,5)**"
      ]
    },
    {
      "metadata": {
        "id": "wW5D_xO-ECiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9a4ac427-b15f-4d69-b0c3-da7ada7920a8"
      },
      "cell_type": "code",
      "source": [
        "X = np.array([[2,6],[3,5],[4,4],[5,3],[6,2],[6,4],[6,6],[8,4],[9,2],[9,3]\n",
        ",[3,3],[4,3],[4,5],[5,5],[7,3],[7,4],[7,5]\n",
        ",[7,2],[10,1],[10,3],[10,5],[11,3],[11,4],[12,2],[13,5]])\n",
        "Y = np.array([1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3])\n",
        "clf = GaussianNB()\n",
        "clf.fit(X, Y)\n",
        "print(\"P1 class:\",clf.predict([[6,5]]))\n",
        "print(\"P2 class:\",clf.predict([[9,4]]))\n",
        "print(\"P3 class:\",clf.predict([[8,5]]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P1 class: [2]\n",
            "P2 class: [3]\n",
            "P3 class: [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wII0vHL_KxaW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Suppose we have a new feature for each instance defined as below\n",
        "If a point is inside the rectangle specified by the (0,0) and (x,y) then the\n",
        "feature value will equal IN, otherwise the feature value will equal OUT.\n",
        "Let us have three regions defined as above using the endpoints (3,2),\n",
        "(6,4) and (9,6).**"
      ]
    },
    {
      "metadata": {
        "id": "roFDtbRAK0Ld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f368219b-e709-4734-c6c0-2d563ce92c23"
      },
      "cell_type": "code",
      "source": [
        "#X-Cor,Y-Cor,In-R1(0,1),In-R2(0,1),In-R3(0,1)\n",
        "X = np.array([\n",
        " [2,6,0,1,1],[3,5,0,1,1],[4,4,0,1,1],[5,3,0,1,1],[6,2,0,1,1],[6,4,0,1,1],[6,6,0,0,1],[8,4,0,0,1],[9,2,0,0,1],[9,3,0,0,1]\n",
        ",[3,3,0,1,1],[4,3,0,1,1],[4,5,0,0,1],[5,5,0,0,1],[7,3,0,0,1],[7,4,0,0,1],[7,5,0,0,1]\n",
        ",[7,2,0,0,1],[10,1,0,0,0],[10,3,0,0,0],[10,5,0,0,0],[11,3,0,0,0],[11,4,0,0,0],[12,2,0,0,0],[13,5,0,0,0]])\n",
        "Y = np.array([1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3])\n",
        "clf = GaussianNB()\n",
        "clf.fit(X, Y)\n",
        "print(\"P1 class:\",clf.predict([[6,5,0,0,1]]))\n",
        "print(\"P2 class:\",clf.predict([[9,4,0,0,1]]))\n",
        "print(\"P3 class:\",clf.predict([[8,5,0,0,1]]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P1 class: [2]\n",
            "P2 class: [1]\n",
            "P3 class: [1]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}